# inits ================================================================================================================================================================================================================== 
random_seed: 0
work_dir: /data/ahmed026/MM_SLT/test
# inits ==================================================================================================================================================================================================================



# idk ==================================================================================================================================================================================================================
batch_size: 8
accumulate_grad_batches: 2
test_batch_size: 2

num_worker: 0
device: cuda:0

feeder: dataset.loader_img.BaseFeeder
feeder_ft: dataset.loader_ft.PrecomputedFeatureDataset

dataset: phoenix2014-T
# idk ==================================================================================================================================================================================================================



# modalities ==================================================================================================================================================================================================================
include_sp: True
include_pose: False
include_mo: False

sp_hidden_size: 768 #swin_sign
# sp_hidden_size: 2048 #ViT
# sp_hidden_size: 3072 #DinoV2

pose_hidden_size: 1024 #KP
# pose_hidden_size: 2048 #HM

mo_hidden_size: 1024
# modalities ==================================================================================================================================================================================================================



# train params ==================================================================================================================================================================================================================
phase: train
num_epoch: 100
num_warmup_epochs: 100
epochs_before_lr_decay: 10
scheduler_patience: 5
validation_interval: 3
patience: 10
monitor_bleu: True
score_dependent_scheduler: True
contrastive: True
include_ctc: False

optimizer_args:
  optimizer: Adam
  base_lr: 0.0001
  learning_ratio: 1
  gamma: 0.2
  weight_decay: 0.0001
  start_epoch: 0

feeder_args:
  mode: 'train'
  datatype: 'video'
  num_gloss: -1
  drop_ratio: 1.0
  frame_interval: 1
  image_scale: 1.0
  input_size: 224
# train params ==================================================================================================================================================================================================================




# model params ==================================================================================================================================================================================================================
slr: modules.slr.SLRModel
slr_weights: /Users/gufran/Developer/Projects/AI/MLLM_SLT/ckpt/swinB_SLR.pt

model: llms.edm_ddp.EDM
# llm: google/flan-t5-xl
llm: facebook/mbart-large-50-many-to-many-mmt

slr_args:
  c2d_type: swinb_mstcn-3
  conv_type: 2
  use_bn: 1
  share_classifier: 1
  weight_norm: True

llm_args:
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.1
  llm_hidden_size: 768
  max_txt_len: 64
  tuning_mode: lora
  prompt: "Translate the given sentence into"
# model params ==================================================================================================================================================================================================================